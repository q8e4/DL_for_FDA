{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2440e3d5",
   "metadata": {},
   "source": [
    "# Functional Neural Network with Adaptive Bases\n",
    "\n",
    "In this notewboook, we present a PyTorch implementation of the model proposed in \"Deep Learning for Functional Data Analysis with Adaptive Basis Layers\", ICML 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3017f4",
   "metadata": {},
   "source": [
    "Unlike many functional networks, AdaFNNs take the raw functional Data as input and learn to apply parsimonious dimension reduction that focuses only on information relevant to the target rather than irrelevant variation in the input. This operation is done through a novel _Basis Layer_ that consists of _basis nodes_ implemented as micro networks. In addition, the inference and training can be done in an end-to-end manner without preprocessing the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affceee",
   "metadata": {},
   "source": [
    "# Implementing AdaFNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca2c60",
   "metadata": {},
   "source": [
    "First, we provide the code for two building blocks, a layer normalization module and feedforward network module (with skipping connection). We start by import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07e35d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730b770",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "The layer normalization was introduced in [Layer Normalization](https://arxiv.org/abs/1607.06450). It is a transposition of Batch Normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7be4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, d, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # d is the normalization dimension\n",
    "        self.d = d\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.randn(d))\n",
    "        self.beta = nn.Parameter(torch.randn(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a torch.Tensor\n",
    "        x = x.to(self.alpha.device)\n",
    "        # avg is the mean value of a layer\n",
    "        avg = x.mean(dim=-1, keepdim=True)\n",
    "        # std is the standard deviation of a layer (eps is added to prevent dividing by zero)\n",
    "        std = x.std(dim=-1, keepdim=True) + self.eps\n",
    "        return (x - avg) / std * self.alpha + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092aa37",
   "metadata": {},
   "source": [
    "Next, we implement a feedforward network module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6e44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, in_d=1, hidden=[4,4,4], dropout=0.1, activation=F.relu):\n",
    "        # in_d      : input dimension, integer\n",
    "        # hidden    : hidden layer dimension, array of integers\n",
    "        # dropout   : dropout probability, a float between 0.0 and 1.0\n",
    "        # activation: activation function at each layer\n",
    "        super().__init__()\n",
    "        self.sigma = activation\n",
    "        dim = [in_d] + hidden + [1]\n",
    "        self.layers = nn.ModuleList([nn.Linear(dim[i-1], dim[i]) for i in range(1, len(dim))])\n",
    "        self.ln = nn.ModuleList([LayerNorm(k) for k in hidden])\n",
    "        self.dp = nn.ModuleList([nn.Dropout(dropout) for _ in range(len(hidden))])\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.to(next(self.layers[0].parameters()).device)  \n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            t = self.layers[i](t)\n",
    "            # skipping connection\n",
    "            t = t + self.ln[i](t)\n",
    "            t = self.sigma(t)\n",
    "            # apply dropout\n",
    "            t = self.dp[i](t)\n",
    "        # linear activation at the last layer\n",
    "        return self.layers[-1](t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58931d84",
   "metadata": {},
   "source": [
    "### Metric operations\n",
    "\n",
    "To build an AdaFNN, we need three new operations: (1) $\\langle f_1, f_2 \\rangle$ (2) $\\| f \\|_2$ and (3) $\\| f \\|_1$. The last two can be established on the first one through: \n",
    "\n",
    "$$ \\| f\\|_2 = \\sqrt{ \\langle f, f \\rangle} $$\n",
    "and \n",
    "$$ \\| f\\|_1 = \\langle 1, |f| \\rangle .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6d199",
   "metadata": {},
   "source": [
    "Since the input is densely observed (equal spacing is not required), the inner product can be approximated by any numerical integration scheme. Here, we will use the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2409c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inner_product(f1, f2, h):\n",
    "    \"\"\"    \n",
    "    f1 - (B, J) : B functions, observed at J time points,\n",
    "    f2 - (B, J) : same as f1\n",
    "    h  - (J-1,1): weights used in the trapezoidal rule\n",
    "    pay attention to dimension\n",
    "    <f1, f2> = sum (h/2) (f1(t{j}) + f2(t{j+1}))\n",
    "    \"\"\"\n",
    "    h.to(f1.device)\n",
    "    prod = f1 * f2 # (B, J = len(h) + 1)\n",
    "    return torch.matmul((prod[:, :-1] + prod[:, 1:]), h.unsqueeze(dim=-1))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e8f32",
   "metadata": {},
   "source": [
    "Then $L_1$ and $L_2$ can be easily implememnted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f718d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _l1(f, h):\n",
    "    # f dimension : ( B bases, J )\n",
    "    B, J = f.size()\n",
    "    return _inner_product(torch.abs(f), torch.ones((B, J), device=device), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dca4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _l2(f, h):\n",
    "    # f dimension : ( B bases, J )\n",
    "    # output dimension - ( B bases, 1 )\n",
    "    return torch.sqrt(_inner_product(f, f, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae9e31",
   "metadata": {},
   "source": [
    "### AdaFNN\n",
    "\n",
    "To prevent the original scale of basis nodes from dominating regularizers, they are normalized.\n",
    "\n",
    "With these in hand, we are ready to present the AdaFNN implmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223940df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaFNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_base=4, base_hidden=[64, 64, 64], grid=(0, 1),\n",
    "                 sub_hidden=[128, 128, 128], dropout=0.1, lambda1=0.0, lambda2=0.0,\n",
    "                 device=None):\n",
    "        \"\"\"\n",
    "        n_base      : number of basis nodes, integer\n",
    "        base_hidden : hidden layers used in each basis node, array of integers\n",
    "        grid        : observation time grid, array of sorted floats including 0.0 and 1.0\n",
    "        sub_hidden  : hidden layers in the subsequent network, array of integers\n",
    "        dropout     : dropout probability\n",
    "        lambda1     : penalty of L1 regularization, a positive real number\n",
    "        lambda2     : penalty of L2 regularization, a positive real number\n",
    "        device      : device for the training\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_base = n_base\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.device = device\n",
    "        # grid should include both end points\n",
    "        grid = np.array(grid)\n",
    "        # send the time grid tensor to device\n",
    "        self.t = torch.tensor(grid).to(device).float()\n",
    "        self.h = torch.tensor(grid[1:] - grid[:-1]).to(device).float()\n",
    "        # instantiate each basis node in the basis layer\n",
    "        self.BL = nn.ModuleList([FeedForward(1, hidden=base_hidden, dropout=dropout, activation=F.selu)\n",
    "                                 for _ in range(n_base)])\n",
    "        # instantiate the subsequent network\n",
    "        self.FF = FeedForward(n_base, sub_hidden, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        B, J = x.size()\n",
    "        assert J == self.h.size()[0] + 1\n",
    "        T = self.t.unsqueeze(dim=-1)\n",
    "        # evaluate the current basis nodes at time grid\n",
    "        self.bases = [basis(T).transpose(-1, -2) for basis in self.BL]\n",
    "        \"\"\"\n",
    "        compute each basis node's L2 norm\n",
    "        normalize basis nodes\n",
    "        \"\"\"\n",
    "        l2_norm = _l2(torch.cat(self.bases, dim=0), self.h).detach()\n",
    "        self.normalized_bases = [self.bases[i] / (l2_norm[i, 0] + 1e-6) for i in range(self.n_base)]\n",
    "        # compute each score <basis_i, f> \n",
    "        score = torch.cat([_inner_product(b.repeat((B, 1)), x, self.h) # (B, 1)\n",
    "                           for b in self.bases], dim=-1) # score dim = (B, n_base)\n",
    "        # take the tensor of scores into the subsequent network\n",
    "        out = self.FF(score)\n",
    "        return out\n",
    "\n",
    "    def R1(self, l1_k):\n",
    "        \"\"\"\n",
    "        L1 regularization\n",
    "        l1_k : number of basis nodes to regularize, integer        \n",
    "        \"\"\"\n",
    "        if self.lambda1 == 0: return torch.zeros(1).to(self.device)\n",
    "        # sample l1_k basis nodes to regularize\n",
    "        selected = np.random.choice(self.n_base, min(l1_k, self.n_base), replace=False)\n",
    "        selected_bases = torch.cat([self.normalized_bases[i] for i in selected], dim=0) # (k, J)\n",
    "        selected_bases.to(self.device)\n",
    "        return self.lambda1 * torch.mean(_l1(selected_bases, self.h))\n",
    "\n",
    "    def R2(self, l2_pairs):\n",
    "        \"\"\"\n",
    "        L2 regularization\n",
    "        l2_pairs : number of pairs to regularize, integer  \n",
    "        \"\"\"\n",
    "        if self.lambda2 == 0 or self.n_base == 1: return torch.zeros(1).to(self.device)\n",
    "        k = min(l2_pairs, self.n_base * (self.n_base - 1) // 2)\n",
    "        f1, f2 = [None] * k, [None] * k\n",
    "        for i in range(k):\n",
    "            a, b = np.random.choice(self.n_base, 2, replace=False)\n",
    "            f1[i], f2[i] = self.normalized_bases[a], self.normalized_bases[b]\n",
    "        return self.lambda2 * torch.mean(torch.abs(_inner_product(torch.cat(f1, dim=0),\n",
    "                                                                  torch.cat(f2, dim=0),\n",
    "                                                                  self.h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6d739",
   "metadata": {},
   "source": [
    "#  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e652727",
   "metadata": {},
   "source": [
    "### Data Generator\n",
    "\n",
    "Data is generated based on the following model:\n",
    "\n",
    "$$ X(t) \\ = \\ \\sum_{k=1}^{50} c_k \\phi_k (t), \\quad t \\in [0,1] ,$$ \n",
    "where terms on the right hand side are defined as:\n",
    "\n",
    "1. $\\phi_1 (t) = 1$ and $ \\phi_k (t) = \\sqrt{2} \\cos ( (k-1) \\pi t)$ for $k = 2, \\dots, 50$.\n",
    "2. $c_k = z_k r_k$, and $r_k$ are i.i.d. uniform random variables on $[-\\sqrt{3}, \\sqrt{3}]$.\n",
    "\n",
    "Case 1: $z_1 = 20$, $z_2 = z_3 = 5$, and $z_k = 1$ for $k \\geq 4$. $y = \\big( \\langle \\phi_3, X \\rangle \\big)^2$.\n",
    "\n",
    "Case 2 and 3: $z_1 = z_3 = 5$, $z_5 = z_{10} = 3$, and $z_k = 1$ for other $k$. $y = \\big( \\langle \\phi_5, X \\rangle \\big)^2$.\n",
    "\n",
    "Case 4: $X$ has the same configurations as Case 2. But $y=\\langle \\beta_2, X \\rangle + \\big( \\langle \\beta_1, X \\rangle \\big)^2$ with\n",
    "\n",
    "$$ \\beta_1 (t) = (4 - 16t) \\cdot 1 \\big\\{ 0 \\leq t \\leq 1/4 \\big\\} $$\n",
    "and\n",
    "$$ \\beta_2 (t) = \\big( 4 - 16|t-1/2| \\big) \\cdot 1 \\big\\{ |t-1/2| \\leq 1/4 \\big\\} .$$\n",
    "\n",
    "For each time point $t$, the observed $X(t)$ may be contaminated by measurement error, i.e.\n",
    "\n",
    "$$ \\tilde{X} (t) = X (t) + \\eta_t, \\quad \\eta_t \\stackrel{i.i.d.}{\\sim} N (0, \\sigma^2_1) .$$\n",
    "\n",
    "The response $y$ may also have noise, i.e. $\\tilde{y} = y + \\epsilon$ where $\\epsilon \\stackrel{i.i.d.}{\\sim} N (0, \\sigma^2_2)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143e254",
   "metadata": {},
   "source": [
    "First, we import necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64017ab6-bb10-4175-ac63-f70e0b188aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be7c3b",
   "metadata": {},
   "source": [
    "Next, we list configurations for each cases and implememnt functions for generating $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5009dcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nz1 = [20, 5, 5] + [1] * 47\\nz2 = [1] * 50\\nz2[0] = z2[2] = 5\\nz2[4] = z2[9] = 3\\nZ = [z1, z2, z2, [1] * 50]\\n\\n\\ndef _phi(k):\\n    if k == 1: return lambda t: np.ones((len(t),))\\n    return lambda t : np.sqrt(2) * np.cos((k-1) * np.pi * t)\\n\\n\\ndef _b1(t):\\n    return (4 - 16 * t) * (0 <= t) * (t <= 1/4)\\n\\n\\ndef _b2(t):\\n    return (4 - 16 * np.abs(1/2 - t)) * (1/4 <= t) * (t <= 3/4)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "z1 = [20, 5, 5] + [1] * 47\n",
    "z2 = [1] * 50\n",
    "z2[0] = z2[2] = 5\n",
    "z2[4] = z2[9] = 3\n",
    "Z = [z1, z2, z2, [1] * 50]\n",
    "\n",
    "\n",
    "def _phi(k):\n",
    "    if k == 1: return lambda t: np.ones((len(t),))\n",
    "    return lambda t : np.sqrt(2) * np.cos((k-1) * np.pi * t)\n",
    "\n",
    "\n",
    "def _b1(t):\n",
    "    return (4 - 16 * t) * (0 <= t) * (t <= 1/4)\n",
    "\n",
    "\n",
    "def _b2(t):\n",
    "    return (4 - 16 * np.abs(1/2 - t)) * (1/4 <= t) * (t <= 3/4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d3a4e",
   "metadata": {},
   "source": [
    "The DataGenerator class generates Data and save it to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, grid, case=1, me=1, err=1):\n",
    "        \"\"\"\n",
    "        grid : array of time points, floats\n",
    "        case : case number, integer\n",
    "        me   : variance of measurement error added to X, non-negative real value\n",
    "        err  : variance of noise added to Y, non-negative real value\n",
    "        \"\"\"\n",
    "        self.t = np.array(grid)\n",
    "        # measurement error\n",
    "        self.me = me\n",
    "        self.err = err\n",
    "        # case - 1\n",
    "        self.case = case\n",
    "        self.z = np.array(Z[case-1])\n",
    "\n",
    "    def generate(self, n=1000):\n",
    "        \"\"\"\n",
    "        n : number of subjects to generate, integer\n",
    "        \"\"\"\n",
    "        # X = sum c_k phi_k\n",
    "        # c_k = z_k r_k, r_k iid unif[-sqrt(3), sqrt(3)]\n",
    "        # generate r\n",
    "        r = np.random.uniform(low=-np.sqrt(3), high=np.sqrt(3), size=(n, 50))\n",
    "        c = r * self.z # (n, 50) elementwise multiplication\n",
    "        phi = np.array([_phi(k)(self.t) for k in range(1, 51)]) # (50, len(self.t))\n",
    "        X = np.matmul(c, phi) # (n, len(self.t))\n",
    "        Y = np.zeros((n, 1))\n",
    "        if self.case == 1:\n",
    "            Y = (c[:, 2]) ** 2\n",
    "        elif self.case == 4:\n",
    "            beta1 = _b1(self.t)\n",
    "            beta2 = _b2(self.t)\n",
    "            h = np.array(self.t[1:] - self.t[:-1]).T\n",
    "            for i in range(n):\n",
    "                Y[i, 0] = self._inner_product(beta2, X[i, :], h) + self._inner_product(beta1, X[i, :], h) ** 2\n",
    "\n",
    "        else: # self.case = 2 or 3\n",
    "            Y = (c[:, 4]) ** 2        \n",
    "        self.X = X + np.random.normal(0, self.me, size=(n, len(self.t)))\n",
    "        self.Y = Y.reshape((n, 1)) + np.random.normal(0, self.err, size=(n, 1))\n",
    "        \n",
    "    def _inner_product(self, f1, f2, h):\n",
    "        prod = f1 * f2\n",
    "        if len(prod.shape) < 2:\n",
    "            prod = prod.reshape((1, -1))\n",
    "        res = np.matmul(prod[:, :-1] + prod[:, 1:], h) / 2\n",
    "        return res\n",
    "\n",
    "    def save(self, folder):\n",
    "        \"\"\"\n",
    "        folder : folder where observations are saved\n",
    "        \"\"\"\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "        X_df = pd.DataFrame(self.X)\n",
    "        Y_df = pd.DataFrame(self.Y)\n",
    "        T_df = pd.DataFrame(self.t.reshape((1, -1)))\n",
    "        X_df.to_csv(folder + \"X.csv\", index=False, header=None)\n",
    "        Y_df.to_csv(folder + \"Y.csv\", index=False, header=None)\n",
    "        T_df.to_csv(folder + \"T.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720e239",
   "metadata": {},
   "source": [
    "The time grid doesn't have to be equally spaced. The model works as long as the time gap is small enough for numerical integration to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98deebb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef random_grid(d=0.02):\\n    \"\"\"\\n    d : maximum time gap between two consecutive time points, float\\n    \"\"\"\\n    grid = [0.0]\\n    while 1.0 - grid[-1] > d:\\n        grid.append(grid[-1] + np.random.uniform(0, d, 1).item())\\n    return grid + [1.0]\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def random_grid(d=0.02):\n",
    "    \"\"\"\n",
    "    d : maximum time gap between two consecutive time points, float\n",
    "    \"\"\"\n",
    "    grid = [0.0]\n",
    "    while 1.0 - grid[-1] > d:\n",
    "        grid.append(grid[-1] + np.random.uniform(0, d, 1).item())\n",
    "    return grid + [1.0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58325a",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "\n",
    "This module reads the Dataset from csv files and split it according to a pre-specific train/valid/test ratio. The Dataset is standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3d8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, batch_size, X, Y, T, split=(8, 1, 1), random_seed=10294):        \n",
    "        \"\"\"\n",
    "        batch_size : batch size, integer\n",
    "        X - (n, J) : pandas.DataFrame for observed functional Data, n - subject number, J - number of time points\n",
    "        Y - (n, 1) : pandas.DataFrame for response\n",
    "        split      : train/valid/test split\n",
    "        random_seed: random seed for training Data re-shuffle\n",
    "        \"\"\"        \n",
    "        self.n, J = X.shape\n",
    "        self.t = T.iloc[0, :].to_numpy()\n",
    "        X, Y = X.values, Y.values\n",
    "\n",
    "        # train/valid/test split\n",
    "        self.batch_size = batch_size\n",
    "        train_n = self.n // sum(split) * split[0]\n",
    "        valid_n = self.n // sum(split) * split[1]\n",
    "        test_n = self.n - train_n - valid_n\n",
    "        self.train_B = train_n // batch_size\n",
    "        self.valid_B = valid_n // batch_size\n",
    "        self.test_B = test_n // batch_size\n",
    "\n",
    "        # random shuffle\n",
    "        np.random.seed(random_seed)\n",
    "        _order = list(range(self.n))\n",
    "        np.random.shuffle(_order)\n",
    "        X = X[_order, :]\n",
    "        Y = Y[_order, :]\n",
    "\n",
    "        # standardize Dataset based on the training Dataset\n",
    "        self.X_standardizer = StandardScaler()\n",
    "        self.Y_standardizer = StandardScaler()\n",
    "\n",
    "        # train/valid/test split\n",
    "        self.train_X = X[:(self.train_B * self.batch_size), :]\n",
    "        self.train_Y = Y[:(self.train_B * self.batch_size), :]\n",
    "        self.X_standardizer.fit(self.train_X)\n",
    "        self.Y_standardizer.fit(self.train_Y)\n",
    "        self.train_X = self.X_standardizer.transform(self.train_X)\n",
    "        self.train_Y = self.Y_standardizer.transform(self.train_Y)\n",
    "\n",
    "        self.valid_X = X[(self.train_B * self.batch_size):((self.train_B + self.valid_B) * self.batch_size), :]\n",
    "        self.valid_Y = Y[(self.train_B * self.batch_size):((self.train_B + self.valid_B) * self.batch_size), :]\n",
    "        self.valid_X = self.X_standardizer.transform(self.valid_X)\n",
    "        self.valid_Y = self.Y_standardizer.transform(self.valid_Y)\n",
    "\n",
    "        self.test_X = X[((self.train_B + self.valid_B) * self.batch_size):, :]\n",
    "        self.test_Y = Y[((self.train_B + self.valid_B) * self.batch_size):, :]\n",
    "        self.test_X = self.X_standardizer.transform(self.test_X)\n",
    "        self.test_Y = self.Y_standardizer.transform(self.test_Y)\n",
    "\n",
    "    def shuffle(self):\n",
    "        # re-shuffle the training Dataset\n",
    "        train_size = self.train_X.shape[0]\n",
    "        new_order = list(range(train_size))\n",
    "        np.random.shuffle(new_order)\n",
    "        self.train_X = self.train_X[new_order, :]\n",
    "        self.train_Y = self.train_Y[new_order, :]\n",
    "\n",
    "    def _batch_generator(self, X, Y, N):\n",
    "\n",
    "        def generator_func():\n",
    "            for i in range(1, N):\n",
    "                x = X[((i - 1) * self.batch_size):((i) * self.batch_size), :]\n",
    "                y = Y[((i - 1) * self.batch_size):((i) * self.batch_size), :]\n",
    "\n",
    "                yield torch.Tensor(x), torch.Tensor(y)\n",
    "\n",
    "        return generator_func()\n",
    "\n",
    "    def get_train_batch(self):\n",
    "        return self._batch_generator(self.train_X, self.train_Y, self.train_B)\n",
    "\n",
    "    def get_valid_batch(self):\n",
    "        return self._batch_generator(self.valid_X, self.valid_Y, self.valid_B)\n",
    "\n",
    "    def get_test_batch(self):\n",
    "        return self._batch_generator(self.test_X, self.test_Y, self.test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49638f",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ba9f4",
   "metadata": {},
   "source": [
    "First, we load necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9040ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaef536",
   "metadata": {},
   "source": [
    "A Dataset will be generated if it is not present. \n",
    "\n",
    "Here, we set the measurement error variance to be 1 and noise variance to be 0.2.\n",
    "\n",
    "**Note**: in this example, we use a flexible time point gap (**not** equal spacing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6f7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif not Path(\"data\").is_dir():\\n    d = 0.02\\n    tp = np.arange(0, 1 + d, d)\\n    tp = random_grid(d)\\n    DatGen = DataGenerator(tp, case=1, me=0.0, err=0.0)\\n    DatGen.generate(4000)\\n    DatGen.save(\"data/\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if not Path(\"data\").is_dir():\n",
    "    d = 0.02\n",
    "    tp = np.arange(0, 1 + d, d)\n",
    "    tp = random_grid(d)\n",
    "    DatGen = DataGenerator(tp, case=1, me=0.0, err=0.0)\n",
    "    DatGen.generate(4000)\n",
    "    DatGen.save(\"data/\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac248ade",
   "metadata": {},
   "source": [
    "The Dataset is loaded and split for training/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d177bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "split = (64, 16, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9c71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './1st_task'\n",
    "\n",
    "X = pd.read_csv(dataset_path + \"/X.csv\", header=None)\n",
    "Y = pd.read_csv(dataset_path + \"/Y.csv\", header=None)\n",
    "T = pd.read_csv(dataset_path + \"/T.csv\", header=None)\n",
    "grid = T.iloc[0, :].to_list()\n",
    "DataLoader = DataLoader(batch_size,  X, Y, T, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d09fa1",
   "metadata": {},
   "source": [
    "Prepare the model and other training configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a0848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up CPU/GPU\n",
    "device = torch.device(\"cuda\") \n",
    "# model configuration\n",
    "\"\"\"\n",
    "You can use a different model by modifing base_hidden, sub_hidden, n_base.\n",
    "\"\"\"\n",
    "base_hidden = [256, 256, 256, 256]\n",
    "sub_hidden = [64, 64]\n",
    "n_base = 2\n",
    "lambda1, l1_k = 0.0, 2\n",
    "lambda2, l2_pairs = 0.0, 3\n",
    "dropout = 0.1\n",
    "save_model_every = 100\n",
    "model = AdaFNN(n_base=n_base,\n",
    "               base_hidden=base_hidden,\n",
    "               grid=grid,\n",
    "               sub_hidden=sub_hidden,\n",
    "               dropout=dropout,\n",
    "               lambda1=lambda1,\n",
    "               lambda2=lambda2,\n",
    "               device=device)\n",
    "# send model to CPU/GPU\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf7301ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "epoch = 500\n",
    "pred_loss_train_history = []\n",
    "total_loss_train_history = []\n",
    "loss_valid_history = []\n",
    "# instantiate an optimizer\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "# use MSE loss\n",
    "compute_loss = torch.nn.MSELoss()\n",
    "min_valid_loss = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cc10f3-db84-4cba-a1e4-fd6934602bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cc291",
   "metadata": {},
   "source": [
    "Create a folder to save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593bd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"train/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e610e",
   "metadata": {},
   "source": [
    "Save and load models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28319be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(folder, k, n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer):\n",
    "    checkpoint = {'n_base': n_base,\n",
    "                  'base_hidden': base_hidden,\n",
    "                  'grid': grid,\n",
    "                  'sub_hidden': sub_hidden,\n",
    "                  'dropout': dropout,\n",
    "                  'lambda1' : lambda1,\n",
    "                  'lambda2' : lambda2,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, folder + str(k) + '_' + 'checkpoint.pth')\n",
    "\n",
    "\n",
    "def load_model(file_path, device):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    model = AdaFNN(n_base=checkpoint['n_base'],\n",
    "                   base_hidden=checkpoint['base_hidden'],\n",
    "                   grid=checkpoint['grid'],\n",
    "                   sub_hidden=checkpoint['sub_hidden'],\n",
    "                   dropout=checkpoint['dropout'],\n",
    "                   lambda1=checkpoint['lambda1'],\n",
    "                   lambda2=checkpoint['lambda2'],\n",
    "                   device=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    _ = model.to(device)\n",
    "    return model, checkpoint['grid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ef584",
   "metadata": {},
   "source": [
    "training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc75468-f375-4cbf-8070-24baf03c2fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "235a85eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 \n",
      " prediction training loss =  0.0868055008065242 validation loss =  0.04903765022754669\n",
      "epoch: 20 \n",
      " prediction training loss =  0.08499864058998916 validation loss =  0.06930323541164399\n",
      "epoch: 30 \n",
      " prediction training loss =  0.10238027257414964 validation loss =  0.05857881456613541\n",
      "epoch: 40 \n",
      " prediction training loss =  0.06946949216608818 validation loss =  0.044351435452699664\n",
      "epoch: 50 \n",
      " prediction training loss =  0.07610381365968631 validation loss =  0.05075121000409126\n",
      "epoch: 60 \n",
      " prediction training loss =  0.0789446713259587 validation loss =  0.05111565664410591\n",
      "epoch: 70 \n",
      " prediction training loss =  0.07469983449062476 validation loss =  0.04258021637797356\n",
      "epoch: 80 \n",
      " prediction training loss =  0.08304619029737435 validation loss =  0.04378670528531074\n",
      "epoch: 90 \n",
      " prediction training loss =  0.06444494469234577 validation loss =  0.047435684502124785\n",
      "epoch: 100 \n",
      " prediction training loss =  0.06591168576135085 validation loss =  0.046865680068731305\n",
      "epoch: 110 \n",
      " prediction training loss =  0.0634003053777493 validation loss =  0.04371964633464813\n",
      "epoch: 120 \n",
      " prediction training loss =  0.07692495411118636 validation loss =  0.044996479898691176\n",
      "epoch: 130 \n",
      " prediction training loss =  0.06276021460787608 validation loss =  0.050182481110095975\n",
      "epoch: 140 \n",
      " prediction training loss =  0.06319753445971471 validation loss =  0.04713091477751732\n",
      "epoch: 150 \n",
      " prediction training loss =  0.09032383618446496 validation loss =  0.11064103990793228\n",
      "epoch: 160 \n",
      " prediction training loss =  0.06436947940920408 validation loss =  0.0446110188961029\n",
      "epoch: 170 \n",
      " prediction training loss =  0.0694340756879403 validation loss =  0.043191103637218474\n",
      "epoch: 180 \n",
      " prediction training loss =  0.0644642125385312 validation loss =  0.05053321123123169\n",
      "epoch: 190 \n",
      " prediction training loss =  0.06284104832089864 validation loss =  0.044271170347929004\n",
      "epoch: 200 \n",
      " prediction training loss =  0.062344058989905395 validation loss =  0.04299295097589493\n",
      "epoch: 210 \n",
      " prediction training loss =  0.06594802611149274 validation loss =  0.042789465934038165\n",
      "epoch: 220 \n",
      " prediction training loss =  0.06059630243824078 validation loss =  0.05916262865066528\n",
      "epoch: 230 \n",
      " prediction training loss =  0.06538215795388588 validation loss =  0.04717510938644409\n",
      "epoch: 240 \n",
      " prediction training loss =  0.06117832015913267 validation loss =  0.04380629509687424\n",
      "epoch: 250 \n",
      " prediction training loss =  0.06516266291817793 validation loss =  0.0639154464006424\n",
      "epoch: 260 \n",
      " prediction training loss =  0.07426938550690046 validation loss =  0.04811746031045914\n",
      "epoch: 270 \n",
      " prediction training loss =  0.0595329378086787 validation loss =  0.0483913004398346\n",
      "epoch: 280 \n",
      " prediction training loss =  0.06204542567810187 validation loss =  0.04674506485462189\n",
      "epoch: 290 \n",
      " prediction training loss =  0.06572965396424899 validation loss =  0.04290972799062729\n",
      "epoch: 300 \n",
      " prediction training loss =  0.06369159241708425 validation loss =  0.04295566827058792\n",
      "epoch: 310 \n",
      " prediction training loss =  0.06588749100382511 validation loss =  0.044778283685445786\n",
      "epoch: 320 \n",
      " prediction training loss =  0.05825794989672991 validation loss =  0.045613383501768114\n",
      "epoch: 330 \n",
      " prediction training loss =  0.05973625612946657 validation loss =  0.04238585494458676\n",
      "epoch: 340 \n",
      " prediction training loss =  0.05597396696416231 validation loss =  0.04358372315764427\n",
      "epoch: 350 \n",
      " prediction training loss =  0.06443192530423403 validation loss =  0.058536773175001146\n",
      "epoch: 360 \n",
      " prediction training loss =  0.06450015199012481 validation loss =  0.045041254907846454\n",
      "epoch: 370 \n",
      " prediction training loss =  0.06196852716115805 validation loss =  0.04846450686454773\n",
      "epoch: 380 \n",
      " prediction training loss =  0.06843684212519573 validation loss =  0.07976792752742767\n",
      "epoch: 390 \n",
      " prediction training loss =  0.07204980890338238 validation loss =  0.06657014563679695\n",
      "epoch: 400 \n",
      " prediction training loss =  0.059691039916987605 validation loss =  0.04340826421976089\n",
      "epoch: 410 \n",
      " prediction training loss =  0.059191519107956156 validation loss =  0.04541091918945313\n",
      "epoch: 420 \n",
      " prediction training loss =  0.059778641192958906 validation loss =  0.04303102418780327\n",
      "epoch: 430 \n",
      " prediction training loss =  0.06101498817308591 validation loss =  0.043086259812116626\n",
      "epoch: 440 \n",
      " prediction training loss =  0.059695727979907624 validation loss =  0.048510171473026276\n",
      "epoch: 450 \n",
      " prediction training loss =  0.060881554149091244 validation loss =  0.04619646444916725\n",
      "epoch: 460 \n",
      " prediction training loss =  0.05872915097727226 validation loss =  0.04253193810582161\n",
      "epoch: 470 \n",
      " prediction training loss =  0.06541035861636584 validation loss =  0.042872560769319536\n",
      "epoch: 480 \n",
      " prediction training loss =  0.05770726931782869 validation loss =  0.05105559378862381\n",
      "epoch: 490 \n",
      " prediction training loss =  0.08030020416929172 validation loss =  0.053054554760456084\n",
      "epoch: 500 \n",
      " prediction training loss =  0.059504990752499834 validation loss =  0.046827057003974916\n",
      "Execution time: 71.34 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for k in range(epoch):\n",
    "\n",
    "    if k and k % save_model_every == 0:\n",
    "        save_model(folder, k, n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer)\n",
    "\n",
    "    pred_loss_train = []\n",
    "    total_loss_train = []\n",
    "    loss_valid = []\n",
    "    DataLoader.shuffle()\n",
    "    # set model training state\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, y) in enumerate(DataLoader.get_train_batch()):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model.forward(x)\n",
    "        loss_pred = compute_loss(out, y)\n",
    "        loss = loss_pred + model.R1(l1_k) + model.R2(l2_pairs)\n",
    "        # record training loss history\n",
    "        total_loss_train.append(loss.item())\n",
    "        pred_loss_train.append(loss_pred.item())\n",
    "\n",
    "        # update parameters using backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss_train_history.append(np.mean(total_loss_train))\n",
    "    pred_loss_train_history.append(np.mean(pred_loss_train))\n",
    "\n",
    "    # model evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x, y in DataLoader.get_valid_batch():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            valid_y = model.forward(x)\n",
    "            valid_loss = compute_loss(valid_y, y)\n",
    "            # print(\"valid - check out: \", check_tensor([valid_loss]))\n",
    "            loss_valid.append(valid_loss.item())\n",
    "\n",
    "    if np.mean(loss_valid) < min_valid_loss:\n",
    "        save_model(folder, \"best\", n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer)\n",
    "        min_valid_loss = np.mean(loss_valid)\n",
    "\n",
    "    loss_valid_history.append(np.mean(loss_valid))\n",
    "    \n",
    "    if (k+1) % 10 == 0:\n",
    "        print(\"epoch:\", k+1, \"\\n\",\n",
    "              \"prediction training loss = \", pred_loss_train_history[-1],\n",
    "              \"validation loss = \", loss_valid_history[-1])\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fa063",
   "metadata": {},
   "source": [
    "Please note that the validation error was computed after a training epoch was complete. So the validation error is generally smaller than the training error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a8efbba-6e57-4903-bcb6-2c18fc01a96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242dd67",
   "metadata": {},
   "source": [
    "Make a loss plot after training finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62cf2f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f99290d2360>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, epoch+1)), total_loss_train_history, label='train_total')\n",
    "plt.plot(list(range(1, epoch+1)), pred_loss_train_history, label='train_pred')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.legend()\n",
    "# plt.savefig('loss_plot.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085d369",
   "metadata": {},
   "source": [
    "After training, to make predictions, we can load the best model and run it on the (test) Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2b0a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(DataLoader, device=torch.device(\"cuda\"), folder=\"train/\"):\n",
    "    ck = folder + \"best_checkpoint.pth\"\n",
    "    # load the best model\n",
    "    model, t = load_model(ck, device)\n",
    "    T = torch.tensor(t).to(device)\n",
    "    t = np.array(t)\n",
    "    \n",
    "    loss_test  = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \"\"\"\n",
    "        Get the performance of the best train model on test Dataset\n",
    "        \"\"\"\n",
    "        for x, y in DataLoader.get_test_batch():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            test_y = model.forward(x)\n",
    "            y_pred.extend(test_y.detach().cpu().numpy().tolist())\n",
    "            test_loss = compute_loss(test_y, y)\n",
    "            loss_test.append(test_loss.item()) \n",
    "        \n",
    "    \"\"\"\n",
    "    Compute the MSE of the test Dataset\n",
    "    \"\"\"\n",
    "    print(\"test accuracy MSE :\", np.mean(loss_test))\n",
    "    \n",
    "    \"\"\"\n",
    "    return the predicted y values by re-scaling the model output\n",
    "    \"\"\"\n",
    "    \n",
    "    return DataLoader.Y_standardizer.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815c040b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy MSE : 0.055093128234148026\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = make_prediction(DataLoader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2.1",
   "language": "python",
   "name": "pytorch2.2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
