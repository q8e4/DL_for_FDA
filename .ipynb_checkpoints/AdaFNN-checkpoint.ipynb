{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2440e3d5",
   "metadata": {},
   "source": [
    "# Functional Neural Network with Adaptive Bases\n",
    "\n",
    "In this notewboook, we present a PyTorch implementation of the model proposed in \"Deep Learning for Functional Data Analysis with Adaptive Basis Layers\", ICML 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3017f4",
   "metadata": {},
   "source": [
    "Unlike many functional networks, AdaFNNs take the raw functional Data as input and learn to apply parsimonious dimension reduction that focuses only on information relevant to the target rather than irrelevant variation in the input. This operation is done through a novel _Basis Layer_ that consists of _basis nodes_ implemented as micro networks. In addition, the inference and training can be done in an end-to-end manner without preprocessing the Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affceee",
   "metadata": {},
   "source": [
    "# Implementing AdaFNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca2c60",
   "metadata": {},
   "source": [
    "First, we provide the code for two building blocks, a layer normalization module and feedforward network module (with skipping connection). We start by import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07e35d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730b770",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "The layer normalization was introduced in [Layer Normalization](https://arxiv.org/abs/1607.06450). It is a transposition of Batch Normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7be4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, d, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # d is the normalization dimension\n",
    "        self.d = d\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.randn(d))\n",
    "        self.beta = nn.Parameter(torch.randn(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a torch.Tensor\n",
    "        x = x.to(self.alpha.device)\n",
    "        # avg is the mean value of a layer\n",
    "        avg = x.mean(dim=-1, keepdim=True)\n",
    "        # std is the standard deviation of a layer (eps is added to prevent dividing by zero)\n",
    "        std = x.std(dim=-1, keepdim=True) + self.eps\n",
    "        return (x - avg) / std * self.alpha + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092aa37",
   "metadata": {},
   "source": [
    "Next, we implement a feedforward network module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6e44b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, in_d=1, hidden=[4,4,4], dropout=0.1, activation=F.relu):\n",
    "        # in_d      : input dimension, integer\n",
    "        # hidden    : hidden layer dimension, array of integers\n",
    "        # dropout   : dropout probability, a float between 0.0 and 1.0\n",
    "        # activation: activation function at each layer\n",
    "        super().__init__()\n",
    "        self.sigma = activation\n",
    "        dim = [in_d] + hidden + [1]\n",
    "        self.layers = nn.ModuleList([nn.Linear(dim[i-1], dim[i]) for i in range(1, len(dim))])\n",
    "        self.ln = nn.ModuleList([LayerNorm(k) for k in hidden])\n",
    "        self.dp = nn.ModuleList([nn.Dropout(dropout) for _ in range(len(hidden))])\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.to(next(self.layers[0].parameters()).device)  \n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            t = self.layers[i](t)\n",
    "            # skipping connection\n",
    "            t = t + self.ln[i](t)\n",
    "            t = self.sigma(t)\n",
    "            # apply dropout\n",
    "            t = self.dp[i](t)\n",
    "        # linear activation at the last layer\n",
    "        return self.layers[-1](t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58931d84",
   "metadata": {},
   "source": [
    "### Metric operations\n",
    "\n",
    "To build an AdaFNN, we need three new operations: (1) $\\langle f_1, f_2 \\rangle$ (2) $\\| f \\|_2$ and (3) $\\| f \\|_1$. The last two can be established on the first one through: \n",
    "\n",
    "$$ \\| f\\|_2 = \\sqrt{ \\langle f, f \\rangle} $$\n",
    "and \n",
    "$$ \\| f\\|_1 = \\langle 1, |f| \\rangle .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6d199",
   "metadata": {},
   "source": [
    "Since the input is densely observed (equal spacing is not required), the inner product can be approximated by any numerical integration scheme. Here, we will use the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2409c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inner_product(f1, f2, h):\n",
    "    \"\"\"    \n",
    "    f1 - (B, J) : B functions, observed at J time points,\n",
    "    f2 - (B, J) : same as f1\n",
    "    h  - (J-1,1): weights used in the trapezoidal rule\n",
    "    pay attention to dimension\n",
    "    <f1, f2> = sum (h/2) (f1(t{j}) + f2(t{j+1}))\n",
    "    \"\"\"\n",
    "    h.to(f1.device)\n",
    "    prod = f1 * f2 # (B, J = len(h) + 1)\n",
    "    return torch.matmul((prod[:, :-1] + prod[:, 1:]), h.unsqueeze(dim=-1))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e8f32",
   "metadata": {},
   "source": [
    "Then $L_1$ and $L_2$ can be easily implememnted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f718d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _l1(f, h):\n",
    "    # f dimension : ( B bases, J )\n",
    "    B, J = f.size()\n",
    "    return _inner_product(torch.abs(f), torch.ones((B, J), device=device), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43dca4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _l2(f, h):\n",
    "    # f dimension : ( B bases, J )\n",
    "    # output dimension - ( B bases, 1 )\n",
    "    return torch.sqrt(_inner_product(f, f, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae9e31",
   "metadata": {},
   "source": [
    "### AdaFNN\n",
    "\n",
    "To prevent the original scale of basis nodes from dominating regularizers, they are normalized.\n",
    "\n",
    "With these in hand, we are ready to present the AdaFNN implmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223940df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaFNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_base=4, base_hidden=[64, 64, 64], grid=(0, 1),\n",
    "                 sub_hidden=[128, 128, 128], dropout=0.1, lambda1=0.0, lambda2=0.0,\n",
    "                 device=None):\n",
    "        \"\"\"\n",
    "        n_base      : number of basis nodes, integer\n",
    "        base_hidden : hidden layers used in each basis node, array of integers\n",
    "        grid        : observation time grid, array of sorted floats including 0.0 and 1.0\n",
    "        sub_hidden  : hidden layers in the subsequent network, array of integers\n",
    "        dropout     : dropout probability\n",
    "        lambda1     : penalty of L1 regularization, a positive real number\n",
    "        lambda2     : penalty of L2 regularization, a positive real number\n",
    "        device      : device for the training\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_base = n_base\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.device = device\n",
    "        # grid should include both end points\n",
    "        grid = np.array(grid)\n",
    "        # send the time grid tensor to device\n",
    "        self.t = torch.tensor(grid).to(device).float()\n",
    "        self.h = torch.tensor(grid[1:] - grid[:-1]).to(device).float()\n",
    "        # instantiate each basis node in the basis layer\n",
    "        self.BL = nn.ModuleList([FeedForward(1, hidden=base_hidden, dropout=dropout, activation=F.selu)\n",
    "                                 for _ in range(n_base)])\n",
    "        # instantiate the subsequent network\n",
    "        self.FF = FeedForward(n_base, sub_hidden, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        B, J = x.size()\n",
    "        assert J == self.h.size()[0] + 1\n",
    "        T = self.t.unsqueeze(dim=-1)\n",
    "        # evaluate the current basis nodes at time grid\n",
    "        self.bases = [basis(T).transpose(-1, -2) for basis in self.BL]\n",
    "        \"\"\"\n",
    "        compute each basis node's L2 norm\n",
    "        normalize basis nodes\n",
    "        \"\"\"\n",
    "        l2_norm = _l2(torch.cat(self.bases, dim=0), self.h).detach()\n",
    "        self.normalized_bases = [self.bases[i] / (l2_norm[i, 0] + 1e-6) for i in range(self.n_base)]\n",
    "        # compute each score <basis_i, f> \n",
    "        score = torch.cat([_inner_product(b.repeat((B, 1)), x, self.h) # (B, 1)\n",
    "                           for b in self.bases], dim=-1) # score dim = (B, n_base)\n",
    "        # take the tensor of scores into the subsequent network\n",
    "        out = self.FF(score)\n",
    "        return out\n",
    "\n",
    "    def R1(self, l1_k):\n",
    "        \"\"\"\n",
    "        L1 regularization\n",
    "        l1_k : number of basis nodes to regularize, integer        \n",
    "        \"\"\"\n",
    "        if self.lambda1 == 0: return torch.zeros(1).to(self.device)\n",
    "        # sample l1_k basis nodes to regularize\n",
    "        selected = np.random.choice(self.n_base, min(l1_k, self.n_base), replace=False)\n",
    "        selected_bases = torch.cat([self.normalized_bases[i] for i in selected], dim=0) # (k, J)\n",
    "        selected_bases.to(self.device)\n",
    "        return self.lambda1 * torch.mean(_l1(selected_bases, self.h))\n",
    "\n",
    "    def R2(self, l2_pairs):\n",
    "        \"\"\"\n",
    "        L2 regularization\n",
    "        l2_pairs : number of pairs to regularize, integer  \n",
    "        \"\"\"\n",
    "        if self.lambda2 == 0 or self.n_base == 1: return torch.zeros(1).to(self.device)\n",
    "        k = min(l2_pairs, self.n_base * (self.n_base - 1) // 2)\n",
    "        f1, f2 = [None] * k, [None] * k\n",
    "        for i in range(k):\n",
    "            a, b = np.random.choice(self.n_base, 2, replace=False)\n",
    "            f1[i], f2[i] = self.normalized_bases[a], self.normalized_bases[b]\n",
    "        return self.lambda2 * torch.mean(torch.abs(_inner_product(torch.cat(f1, dim=0),\n",
    "                                                                  torch.cat(f2, dim=0),\n",
    "                                                                  self.h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f6d739",
   "metadata": {},
   "source": [
    "#  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e652727",
   "metadata": {},
   "source": [
    "### Data Generator\n",
    "\n",
    "Data is generated based on the following model:\n",
    "\n",
    "$$ X(t) \\ = \\ \\sum_{k=1}^{50} c_k \\phi_k (t), \\quad t \\in [0,1] ,$$ \n",
    "where terms on the right hand side are defined as:\n",
    "\n",
    "1. $\\phi_1 (t) = 1$ and $ \\phi_k (t) = \\sqrt{2} \\cos ( (k-1) \\pi t)$ for $k = 2, \\dots, 50$.\n",
    "2. $c_k = z_k r_k$, and $r_k$ are i.i.d. uniform random variables on $[-\\sqrt{3}, \\sqrt{3}]$.\n",
    "\n",
    "Case 1: $z_1 = 20$, $z_2 = z_3 = 5$, and $z_k = 1$ for $k \\geq 4$. $y = \\big( \\langle \\phi_3, X \\rangle \\big)^2$.\n",
    "\n",
    "Case 2 and 3: $z_1 = z_3 = 5$, $z_5 = z_{10} = 3$, and $z_k = 1$ for other $k$. $y = \\big( \\langle \\phi_5, X \\rangle \\big)^2$.\n",
    "\n",
    "Case 4: $X$ has the same configurations as Case 2. But $y=\\langle \\beta_2, X \\rangle + \\big( \\langle \\beta_1, X \\rangle \\big)^2$ with\n",
    "\n",
    "$$ \\beta_1 (t) = (4 - 16t) \\cdot 1 \\big\\{ 0 \\leq t \\leq 1/4 \\big\\} $$\n",
    "and\n",
    "$$ \\beta_2 (t) = \\big( 4 - 16|t-1/2| \\big) \\cdot 1 \\big\\{ |t-1/2| \\leq 1/4 \\big\\} .$$\n",
    "\n",
    "For each time point $t$, the observed $X(t)$ may be contaminated by measurement error, i.e.\n",
    "\n",
    "$$ \\tilde{X} (t) = X (t) + \\eta_t, \\quad \\eta_t \\stackrel{i.i.d.}{\\sim} N (0, \\sigma^2_1) .$$\n",
    "\n",
    "The response $y$ may also have noise, i.e. $\\tilde{y} = y + \\epsilon$ where $\\epsilon \\stackrel{i.i.d.}{\\sim} N (0, \\sigma^2_2)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143e254",
   "metadata": {},
   "source": [
    "First, we import necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64017ab6-bb10-4175-ac63-f70e0b188aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be7c3b",
   "metadata": {},
   "source": [
    "Next, we list configurations for each cases and implememnt functions for generating $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5009dcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nz1 = [20, 5, 5] + [1] * 47\\nz2 = [1] * 50\\nz2[0] = z2[2] = 5\\nz2[4] = z2[9] = 3\\nZ = [z1, z2, z2, [1] * 50]\\n\\n\\ndef _phi(k):\\n    if k == 1: return lambda t: np.ones((len(t),))\\n    return lambda t : np.sqrt(2) * np.cos((k-1) * np.pi * t)\\n\\n\\ndef _b1(t):\\n    return (4 - 16 * t) * (0 <= t) * (t <= 1/4)\\n\\n\\ndef _b2(t):\\n    return (4 - 16 * np.abs(1/2 - t)) * (1/4 <= t) * (t <= 3/4)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "z1 = [20, 5, 5] + [1] * 47\n",
    "z2 = [1] * 50\n",
    "z2[0] = z2[2] = 5\n",
    "z2[4] = z2[9] = 3\n",
    "Z = [z1, z2, z2, [1] * 50]\n",
    "\n",
    "\n",
    "def _phi(k):\n",
    "    if k == 1: return lambda t: np.ones((len(t),))\n",
    "    return lambda t : np.sqrt(2) * np.cos((k-1) * np.pi * t)\n",
    "\n",
    "\n",
    "def _b1(t):\n",
    "    return (4 - 16 * t) * (0 <= t) * (t <= 1/4)\n",
    "\n",
    "\n",
    "def _b2(t):\n",
    "    return (4 - 16 * np.abs(1/2 - t)) * (1/4 <= t) * (t <= 3/4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d3a4e",
   "metadata": {},
   "source": [
    "The DataGenerator class generates Data and save it to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb165a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "\n",
    "    def __init__(self, grid, case=1, me=1, err=1):\n",
    "        \"\"\"\n",
    "        grid : array of time points, floats\n",
    "        case : case number, integer\n",
    "        me   : variance of measurement error added to X, non-negative real value\n",
    "        err  : variance of noise added to Y, non-negative real value\n",
    "        \"\"\"\n",
    "        self.t = np.array(grid)\n",
    "        # measurement error\n",
    "        self.me = me\n",
    "        self.err = err\n",
    "        # case - 1\n",
    "        self.case = case\n",
    "        self.z = np.array(Z[case-1])\n",
    "\n",
    "    def generate(self, n=1000):\n",
    "        \"\"\"\n",
    "        n : number of subjects to generate, integer\n",
    "        \"\"\"\n",
    "        # X = sum c_k phi_k\n",
    "        # c_k = z_k r_k, r_k iid unif[-sqrt(3), sqrt(3)]\n",
    "        # generate r\n",
    "        r = np.random.uniform(low=-np.sqrt(3), high=np.sqrt(3), size=(n, 50))\n",
    "        c = r * self.z # (n, 50) elementwise multiplication\n",
    "        phi = np.array([_phi(k)(self.t) for k in range(1, 51)]) # (50, len(self.t))\n",
    "        X = np.matmul(c, phi) # (n, len(self.t))\n",
    "        Y = np.zeros((n, 1))\n",
    "        if self.case == 1:\n",
    "            Y = (c[:, 2]) ** 2\n",
    "        elif self.case == 4:\n",
    "            beta1 = _b1(self.t)\n",
    "            beta2 = _b2(self.t)\n",
    "            h = np.array(self.t[1:] - self.t[:-1]).T\n",
    "            for i in range(n):\n",
    "                Y[i, 0] = self._inner_product(beta2, X[i, :], h) + self._inner_product(beta1, X[i, :], h) ** 2\n",
    "\n",
    "        else: # self.case = 2 or 3\n",
    "            Y = (c[:, 4]) ** 2        \n",
    "        self.X = X + np.random.normal(0, self.me, size=(n, len(self.t)))\n",
    "        self.Y = Y.reshape((n, 1)) + np.random.normal(0, self.err, size=(n, 1))\n",
    "        \n",
    "    def _inner_product(self, f1, f2, h):\n",
    "        prod = f1 * f2\n",
    "        if len(prod.shape) < 2:\n",
    "            prod = prod.reshape((1, -1))\n",
    "        res = np.matmul(prod[:, :-1] + prod[:, 1:], h) / 2\n",
    "        return res\n",
    "\n",
    "    def save(self, folder):\n",
    "        \"\"\"\n",
    "        folder : folder where observations are saved\n",
    "        \"\"\"\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "        X_df = pd.DataFrame(self.X)\n",
    "        Y_df = pd.DataFrame(self.Y)\n",
    "        T_df = pd.DataFrame(self.t.reshape((1, -1)))\n",
    "        X_df.to_csv(folder + \"X.csv\", index=False, header=None)\n",
    "        Y_df.to_csv(folder + \"Y.csv\", index=False, header=None)\n",
    "        T_df.to_csv(folder + \"T.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720e239",
   "metadata": {},
   "source": [
    "The time grid doesn't have to be equally spaced. The model works as long as the time gap is small enough for numerical integration to work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98deebb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef random_grid(d=0.02):\\n    \"\"\"\\n    d : maximum time gap between two consecutive time points, float\\n    \"\"\"\\n    grid = [0.0]\\n    while 1.0 - grid[-1] > d:\\n        grid.append(grid[-1] + np.random.uniform(0, d, 1).item())\\n    return grid + [1.0]\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def random_grid(d=0.02):\n",
    "    \"\"\"\n",
    "    d : maximum time gap between two consecutive time points, float\n",
    "    \"\"\"\n",
    "    grid = [0.0]\n",
    "    while 1.0 - grid[-1] > d:\n",
    "        grid.append(grid[-1] + np.random.uniform(0, d, 1).item())\n",
    "    return grid + [1.0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58325a",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "\n",
    "This module reads the Dataset from csv files and split it according to a pre-specific train/valid/test ratio. The Dataset is standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3d8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, batch_size, X, Y, T, split=(8, 1, 1), random_seed=10294):        \n",
    "        \"\"\"\n",
    "        batch_size : batch size, integer\n",
    "        X - (n, J) : pandas.DataFrame for observed functional Data, n - subject number, J - number of time points\n",
    "        Y - (n, 1) : pandas.DataFrame for response\n",
    "        split      : train/valid/test split\n",
    "        random_seed: random seed for training Data re-shuffle\n",
    "        \"\"\"        \n",
    "        self.n, J = X.shape\n",
    "        self.t = T.iloc[0, :].to_numpy()\n",
    "        X, Y = X.values, Y.values\n",
    "\n",
    "        # train/valid/test split\n",
    "        self.batch_size = batch_size\n",
    "        train_n = self.n // sum(split) * split[0]\n",
    "        valid_n = self.n // sum(split) * split[1]\n",
    "        test_n = self.n - train_n - valid_n\n",
    "        self.train_B = train_n // batch_size\n",
    "        self.valid_B = valid_n // batch_size\n",
    "        self.test_B = test_n // batch_size\n",
    "\n",
    "        # random shuffle\n",
    "        np.random.seed(random_seed)\n",
    "        _order = list(range(self.n))\n",
    "        np.random.shuffle(_order)\n",
    "        X = X[_order, :]\n",
    "        Y = Y[_order, :]\n",
    "\n",
    "        # standardize Dataset based on the training Dataset\n",
    "        self.X_standardizer = StandardScaler()\n",
    "        self.Y_standardizer = StandardScaler()\n",
    "\n",
    "        # train/valid/test split\n",
    "        self.train_X = X[:(self.train_B * self.batch_size), :]\n",
    "        self.train_Y = Y[:(self.train_B * self.batch_size), :]\n",
    "        self.X_standardizer.fit(self.train_X)\n",
    "        self.Y_standardizer.fit(self.train_Y)\n",
    "        self.train_X = self.X_standardizer.transform(self.train_X)\n",
    "        self.train_Y = self.Y_standardizer.transform(self.train_Y)\n",
    "\n",
    "        self.valid_X = X[(self.train_B * self.batch_size):((self.train_B + self.valid_B) * self.batch_size), :]\n",
    "        self.valid_Y = Y[(self.train_B * self.batch_size):((self.train_B + self.valid_B) * self.batch_size), :]\n",
    "        self.valid_X = self.X_standardizer.transform(self.valid_X)\n",
    "        self.valid_Y = self.Y_standardizer.transform(self.valid_Y)\n",
    "\n",
    "        self.test_X = X[((self.train_B + self.valid_B) * self.batch_size):, :]\n",
    "        self.test_Y = Y[((self.train_B + self.valid_B) * self.batch_size):, :]\n",
    "        self.test_X = self.X_standardizer.transform(self.test_X)\n",
    "        self.test_Y = self.Y_standardizer.transform(self.test_Y)\n",
    "\n",
    "    def shuffle(self):\n",
    "        # re-shuffle the training Dataset\n",
    "        train_size = self.train_X.shape[0]\n",
    "        new_order = list(range(train_size))\n",
    "        np.random.shuffle(new_order)\n",
    "        self.train_X = self.train_X[new_order, :]\n",
    "        self.train_Y = self.train_Y[new_order, :]\n",
    "\n",
    "    def _batch_generator(self, X, Y, N):\n",
    "\n",
    "        def generator_func():\n",
    "            for i in range(1, N):\n",
    "                x = X[((i - 1) * self.batch_size):((i) * self.batch_size), :]\n",
    "                y = Y[((i - 1) * self.batch_size):((i) * self.batch_size), :]\n",
    "\n",
    "                yield torch.Tensor(x), torch.Tensor(y)\n",
    "\n",
    "        return generator_func()\n",
    "\n",
    "    def get_train_batch(self):\n",
    "        return self._batch_generator(self.train_X, self.train_Y, self.train_B)\n",
    "\n",
    "    def get_valid_batch(self):\n",
    "        return self._batch_generator(self.valid_X, self.valid_Y, self.valid_B)\n",
    "\n",
    "    def get_test_batch(self):\n",
    "        return self._batch_generator(self.test_X, self.test_Y, self.test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49638f",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ba9f4",
   "metadata": {},
   "source": [
    "First, we load necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9040ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaef536",
   "metadata": {},
   "source": [
    "A Dataset will be generated if it is not present. \n",
    "\n",
    "Here, we set the measurement error variance to be 1 and noise variance to be 0.2.\n",
    "\n",
    "**Note**: in this example, we use a flexible time point gap (**not** equal spacing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6f7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif not Path(\"data\").is_dir():\\n    d = 0.02\\n    tp = np.arange(0, 1 + d, d)\\n    tp = random_grid(d)\\n    DatGen = DataGenerator(tp, case=1, me=0.0, err=0.0)\\n    DatGen.generate(4000)\\n    DatGen.save(\"data/\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if not Path(\"data\").is_dir():\n",
    "    d = 0.02\n",
    "    tp = np.arange(0, 1 + d, d)\n",
    "    tp = random_grid(d)\n",
    "    DatGen = DataGenerator(tp, case=1, me=0.0, err=0.0)\n",
    "    DatGen.generate(4000)\n",
    "    DatGen.save(\"data/\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac248ade",
   "metadata": {},
   "source": [
    "The Dataset is loaded and split for training/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d177bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "split = (64, 16, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce9c71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './1st_task'\n",
    "\n",
    "X = pd.read_csv(dataset_path + \"/X.csv\", header=None)\n",
    "Y = pd.read_csv(dataset_path + \"/Y.csv\", header=None)\n",
    "T = pd.read_csv(dataset_path + \"/T.csv\", header=None)\n",
    "grid = T.iloc[0, :].to_list()\n",
    "DataLoader = DataLoader(batch_size,  X, Y, T, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d09fa1",
   "metadata": {},
   "source": [
    "Prepare the model and other training configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a0848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up CPU/GPU\n",
    "device = torch.device(\"cuda\") \n",
    "# model configuration\n",
    "\"\"\"\n",
    "You can use a different model by modifing base_hidden, sub_hidden, n_base.\n",
    "\"\"\"\n",
    "base_hidden = [64, 64, 64]\n",
    "sub_hidden = [128, 128, 128]\n",
    "n_base = 4\n",
    "lambda1, l1_k = 0.0, 2\n",
    "lambda2, l2_pairs = 0.0, 3\n",
    "dropout = 0.1\n",
    "save_model_every = 100\n",
    "model = AdaFNN(n_base=n_base,\n",
    "               base_hidden=base_hidden,\n",
    "               grid=grid,\n",
    "               sub_hidden=sub_hidden,\n",
    "               dropout=dropout,\n",
    "               lambda1=lambda1,\n",
    "               lambda2=lambda2,\n",
    "               device=device)\n",
    "# send model to CPU/GPU\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf7301ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "epoch = 500\n",
    "pred_loss_train_history = []\n",
    "total_loss_train_history = []\n",
    "loss_valid_history = []\n",
    "# instantiate an optimizer\n",
    "optimizer = Adam(model.parameters(), lr=3e-4)\n",
    "# use MSE loss\n",
    "compute_loss = torch.nn.MSELoss()\n",
    "min_valid_loss = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cc10f3-db84-4cba-a1e4-fd6934602bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564cc291",
   "metadata": {},
   "source": [
    "Create a folder to save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593bd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"train/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e610e",
   "metadata": {},
   "source": [
    "Save and load models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28319be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(folder, k, n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer):\n",
    "    checkpoint = {'n_base': n_base,\n",
    "                  'base_hidden': base_hidden,\n",
    "                  'grid': grid,\n",
    "                  'sub_hidden': sub_hidden,\n",
    "                  'dropout': dropout,\n",
    "                  'lambda1' : lambda1,\n",
    "                  'lambda2' : lambda2,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict()}\n",
    "    torch.save(checkpoint, folder + str(k) + '_' + 'checkpoint.pth')\n",
    "\n",
    "\n",
    "def load_model(file_path, device):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    model = AdaFNN(n_base=checkpoint['n_base'],\n",
    "                   base_hidden=checkpoint['base_hidden'],\n",
    "                   grid=checkpoint['grid'],\n",
    "                   sub_hidden=checkpoint['sub_hidden'],\n",
    "                   dropout=checkpoint['dropout'],\n",
    "                   lambda1=checkpoint['lambda1'],\n",
    "                   lambda2=checkpoint['lambda2'],\n",
    "                   device=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    _ = model.to(device)\n",
    "    return model, checkpoint['grid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74ef584",
   "metadata": {},
   "source": [
    "training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc75468-f375-4cbf-8070-24baf03c2fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "235a85eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 \n",
      " prediction training loss =  0.07973540789232804 validation loss =  0.0453200526535511\n",
      "epoch: 20 \n",
      " prediction training loss =  0.07294360999591075 validation loss =  0.0568354919552803\n",
      "epoch: 30 \n",
      " prediction training loss =  0.086681295472842 validation loss =  0.05276251211762428\n",
      "epoch: 40 \n",
      " prediction training loss =  0.06627442859686337 validation loss =  0.04623707830905914\n",
      "epoch: 50 \n",
      " prediction training loss =  0.07571012956591752 validation loss =  0.04306499026715756\n",
      "epoch: 60 \n",
      " prediction training loss =  0.061486946992003 validation loss =  0.04222462214529514\n",
      "epoch: 70 \n",
      " prediction training loss =  0.06125657224597839 validation loss =  0.0420115202665329\n",
      "epoch: 80 \n",
      " prediction training loss =  0.06476961477444722 validation loss =  0.0429193377494812\n",
      "epoch: 90 \n",
      " prediction training loss =  0.06336806642894562 validation loss =  0.04441431015729904\n",
      "epoch: 100 \n",
      " prediction training loss =  0.06065400095226673 validation loss =  0.043080373853445056\n",
      "epoch: 110 \n",
      " prediction training loss =  0.06761197459239227 validation loss =  0.045315834879875186\n",
      "epoch: 120 \n",
      " prediction training loss =  0.0608234226417083 validation loss =  0.04287852197885513\n",
      "epoch: 130 \n",
      " prediction training loss =  0.06263181380927563 validation loss =  0.04209821745753288\n",
      "epoch: 140 \n",
      " prediction training loss =  0.06861272970071206 validation loss =  0.04624373912811279\n",
      "epoch: 150 \n",
      " prediction training loss =  0.06169812846928835 validation loss =  0.04259320609271526\n",
      "epoch: 160 \n",
      " prediction training loss =  0.06189624212968808 validation loss =  0.04169082194566727\n",
      "epoch: 170 \n",
      " prediction training loss =  0.06347729609562801 validation loss =  0.04421801641583443\n",
      "epoch: 180 \n",
      " prediction training loss =  0.07288323672345051 validation loss =  0.05548930615186691\n",
      "epoch: 190 \n",
      " prediction training loss =  0.06399055233655068 validation loss =  0.043606311082839966\n",
      "epoch: 200 \n",
      " prediction training loss =  0.057901390111790255 validation loss =  0.04288254976272583\n",
      "epoch: 210 \n",
      " prediction training loss =  0.07957514726485197 validation loss =  0.044674257189035414\n",
      "epoch: 220 \n",
      " prediction training loss =  0.0675824129094298 validation loss =  0.04868688359856606\n",
      "epoch: 230 \n",
      " prediction training loss =  0.07585948103895554 validation loss =  0.05106175318360329\n",
      "epoch: 240 \n",
      " prediction training loss =  0.06350680999457836 validation loss =  0.046196556836366656\n",
      "epoch: 250 \n",
      " prediction training loss =  0.06085347176457827 validation loss =  0.04256138205528259\n",
      "epoch: 260 \n",
      " prediction training loss =  0.06216028017493395 validation loss =  0.0438323013484478\n",
      "epoch: 270 \n",
      " prediction training loss =  0.060635010783488937 validation loss =  0.04179905205965042\n",
      "epoch: 280 \n",
      " prediction training loss =  0.06985568011609408 validation loss =  0.04357578605413437\n",
      "epoch: 290 \n",
      " prediction training loss =  0.06558409103980431 validation loss =  0.04182912185788155\n",
      "epoch: 300 \n",
      " prediction training loss =  0.06847083332160345 validation loss =  0.056527496129274366\n",
      "epoch: 310 \n",
      " prediction training loss =  0.06585898923759277 validation loss =  0.06192555725574493\n",
      "epoch: 320 \n",
      " prediction training loss =  0.06341876791646847 validation loss =  0.04805519506335258\n",
      "epoch: 330 \n",
      " prediction training loss =  0.06013375348769701 validation loss =  0.043188754469156265\n",
      "epoch: 340 \n",
      " prediction training loss =  0.0539717458618375 validation loss =  0.04285472296178341\n",
      "epoch: 350 \n",
      " prediction training loss =  0.0849887621947206 validation loss =  0.056522098183631894\n",
      "epoch: 360 \n",
      " prediction training loss =  0.06282736117450091 validation loss =  0.04225960373878479\n",
      "epoch: 370 \n",
      " prediction training loss =  0.061664250965874925 validation loss =  0.042806234955787656\n",
      "epoch: 380 \n",
      " prediction training loss =  0.05892437717948969 validation loss =  0.04122395217418671\n",
      "epoch: 390 \n",
      " prediction training loss =  0.05763699787740524 validation loss =  0.042110752686858176\n",
      "epoch: 400 \n",
      " prediction training loss =  0.05683225078078417 validation loss =  0.040862027928233145\n",
      "epoch: 410 \n",
      " prediction training loss =  0.06922230432526423 validation loss =  0.043970154225826265\n",
      "epoch: 420 \n",
      " prediction training loss =  0.06188089966487426 validation loss =  0.04053944386541843\n",
      "epoch: 430 \n",
      " prediction training loss =  0.06911587951561579 validation loss =  0.05092712789773941\n",
      "epoch: 440 \n",
      " prediction training loss =  0.06063794602568333 validation loss =  0.0450447965413332\n",
      "epoch: 450 \n",
      " prediction training loss =  0.05586643767758058 validation loss =  0.0410801850259304\n",
      "epoch: 460 \n",
      " prediction training loss =  0.047560093709482595 validation loss =  0.04250667430460453\n",
      "epoch: 470 \n",
      " prediction training loss =  0.06364167682253398 validation loss =  0.043430101871490476\n",
      "epoch: 480 \n",
      " prediction training loss =  0.06241612659337429 validation loss =  0.04473629593849182\n",
      "epoch: 490 \n",
      " prediction training loss =  0.059969747152466044 validation loss =  0.040909912437200546\n",
      "epoch: 500 \n",
      " prediction training loss =  0.06596187294389193 validation loss =  0.04366515427827835\n",
      "Execution time: 102.02 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for k in range(epoch):\n",
    "\n",
    "    if k and k % save_model_every == 0:\n",
    "        save_model(folder, k, n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer)\n",
    "\n",
    "    pred_loss_train = []\n",
    "    total_loss_train = []\n",
    "    loss_valid = []\n",
    "    DataLoader.shuffle()\n",
    "    # set model training state\n",
    "    model.train()\n",
    "\n",
    "    for i, (x, y) in enumerate(DataLoader.get_train_batch()):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model.forward(x)\n",
    "        loss_pred = compute_loss(out, y)\n",
    "        loss = loss_pred + model.R1(l1_k) + model.R2(l2_pairs)\n",
    "        # record training loss history\n",
    "        total_loss_train.append(loss.item())\n",
    "        pred_loss_train.append(loss_pred.item())\n",
    "\n",
    "        # update parameters using backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss_train_history.append(np.mean(total_loss_train))\n",
    "    pred_loss_train_history.append(np.mean(pred_loss_train))\n",
    "\n",
    "    # model evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x, y in DataLoader.get_valid_batch():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            valid_y = model.forward(x)\n",
    "            valid_loss = compute_loss(valid_y, y)\n",
    "            # print(\"valid - check out: \", check_tensor([valid_loss]))\n",
    "            loss_valid.append(valid_loss.item())\n",
    "\n",
    "    if np.mean(loss_valid) < min_valid_loss:\n",
    "        save_model(folder, \"best\", n_base, base_hidden, grid, sub_hidden, dropout, lambda1, lambda2, model, optimizer)\n",
    "        min_valid_loss = np.mean(loss_valid)\n",
    "\n",
    "    loss_valid_history.append(np.mean(loss_valid))\n",
    "    \n",
    "    if (k+1) % 10 == 0:\n",
    "        print(\"epoch:\", k+1, \"\\n\",\n",
    "              \"prediction training loss = \", pred_loss_train_history[-1],\n",
    "              \"validation loss = \", loss_valid_history[-1])\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fa063",
   "metadata": {},
   "source": [
    "Please note that the validation error was computed after a training epoch was complete. So the validation error is generally smaller than the training error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a8efbba-6e57-4903-bcb6-2c18fc01a96b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7242dd67",
   "metadata": {},
   "source": [
    "Make a loss plot after training finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62cf2f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd14c9e7530>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, epoch+1)), total_loss_train_history, label='train_total')\n",
    "plt.plot(list(range(1, epoch+1)), pred_loss_train_history, label='train_pred')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.legend()\n",
    "# plt.savefig('loss_plot.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085d369",
   "metadata": {},
   "source": [
    "After training, to make predictions, we can load the best model and run it on the (test) Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2b0a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(DataLoader, device=torch.device(\"cuda\"), folder=\"train/\"):\n",
    "    ck = folder + \"best_checkpoint.pth\"\n",
    "    # load the best model\n",
    "    model, t = load_model(ck, device)\n",
    "    T = torch.tensor(t).to(device)\n",
    "    t = np.array(t)\n",
    "    \n",
    "    loss_test  = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \"\"\"\n",
    "        Get the performance of the best train model on test Dataset\n",
    "        \"\"\"\n",
    "        for x, y in DataLoader.get_test_batch():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            test_y = model.forward(x)\n",
    "            y_pred.extend(test_y.detach().cpu().numpy().tolist())\n",
    "            test_loss = compute_loss(test_y, y)\n",
    "            loss_test.append(test_loss.item()) \n",
    "        \n",
    "    \"\"\"\n",
    "    Compute the MSE of the test Dataset\n",
    "    \"\"\"\n",
    "    print(\"test accuracy MSE :\", np.mean(loss_test))\n",
    "    \n",
    "    \"\"\"\n",
    "    return the predicted y values by re-scaling the model output\n",
    "    \"\"\"\n",
    "    \n",
    "    return DataLoader.Y_standardizer.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815c040b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy MSE : 0.05508957803249359\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = make_prediction(DataLoader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2.1",
   "language": "python",
   "name": "pytorch2.2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
